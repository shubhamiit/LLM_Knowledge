{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alligned Instruction Finetuned T5 Model with human values [Lower Toxicity] using RLHF + PEFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using hate speech reward model by Facebook\n",
    "2. Using PPO to finetune and reduce toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# #install libs\n",
    "\n",
    "# %pip install --upgrade pip\n",
    "# %pip install --disable-pip-version-check \\\n",
    "#     torch==1.13.1 \\\n",
    "#     torchdata==0.5.1 --quiet\n",
    "\n",
    "# %pip install \\\n",
    "#     transformers==4.27.2 \\\n",
    "#     datasets==2.11.0 \\\n",
    "#     evaluate==0.4.0 \\\n",
    "#     rouge_score==0.1.2 \\\n",
    "#     loralib==0.1.1 \\\n",
    "#     peft==0.3.0 --quiet\n",
    "\n",
    "# %pip install trl==0.4.4 --quiet  # RLHF lib provided by HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/LLM3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import libs\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, AutoModelForSequenceClassification\n",
    "from peft import PeftModel, PeftConfig, LoraConfig, TaskType\n",
    "\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead\n",
    "from trl import create_reference_model\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "TIME=str(int(time.time()))\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7faa29d665f0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshubsoni\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/batch/tasks/shared/LS_root/mounts/clusters/sonishubhamnc6/code/Users/sonishubham/wandb/run-20231004_093217-gjbuwfvr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shubsoni/T5-RLHF-peft-finetuning/runs/gjbuwfvr' target=\"_blank\">legendary-totem-3</a></strong> to <a href='https://wandb.ai/shubsoni/T5-RLHF-peft-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shubsoni/T5-RLHF-peft-finetuning' target=\"_blank\">https://wandb.ai/shubsoni/T5-RLHF-peft-finetuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shubsoni/T5-RLHF-peft-finetuning/runs/gjbuwfvr' target=\"_blank\">https://wandb.ai/shubsoni/T5-RLHF-peft-finetuning/runs/gjbuwfvr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/shubsoni/T5-RLHF-peft-finetuning/runs/gjbuwfvr?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fa98ef3ab90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add wandb logging\n",
    "# %pip install wandb\n",
    "import wandb\n",
    "wandb.init(project=\"T5-RLHF-peft-finetuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.65k/4.65k [00:00<00:00, 8.01MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/knkarthick--dialogsum to /home/azureuser/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-cd36827d3490488d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files:   0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11.3M/11.3M [00:00<00:00, 22.5MB/s]\n",
      "Downloading data: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.35M/1.35M [00:00<00:00, 29.9MB/s]\n",
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 442k/442k [00:00<00:00, 53.4MB/s]\n",
      "Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.06it/s]\n",
      "Extracting data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1488.57it/s]\n",
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/azureuser/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-cd36827d3490488d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 199.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"google/flan-t5-base\"\n",
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "\n",
    "dataset_original = load_dataset(huggingface_dataset_name)\n",
    "dataset_original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "\n",
    "def print_number_of_trainable_parameters(model):\n",
    "    trainable_params =0\n",
    "    all_model_params =0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params+=param.numel()\n",
    "    return f\"trainable model parameters: {trainable_params}\\nall model parameters: {all_model_params} \\n. percentage trainable parameters: {trainable_params*(100)/all_model_params:.2f}%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/azureuser/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-cd36827d3490488d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Filter:   0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | 0/12460 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
       "        num_rows: 8017\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
       "        num_rows: 2005\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_dataset(model_name, dataset_name, input_min_length, input_max_length):\n",
    "    \n",
    "    dataset = load_dataset(dataset_name, split=\"train\")\n",
    "    \n",
    "\n",
    "    #use only dialogues of fixed length\n",
    "    dataset = dataset.filter(lambda x: len(x[\"dialogue\"]) > input_min_length and len(x[\"dialogue\"]) <= input_max_length, batched= False)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "    def tokenize(sample):\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{sample[\"dialogue\"]}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "        sample[\"input_ids\"] = tokenizer.encode(prompt)\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "    \n",
    "    dataset = dataset.map(tokenize, batched=False)\n",
    "    dataset.set_format(type=\"torch\")\n",
    "\n",
    "    dataset_splits = dataset.train_test_split(test_size=0.2, shuffle=False, seed =42)\n",
    "\n",
    "    return dataset_splits\n",
    "\n",
    "dataset = build_dataset(model_name=model_name, dataset_name=huggingface_dataset_name, input_max_length=1000, input_min_length=200)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the PEFT model trained earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'trainable model parameters: 884736\\nall model parameters: 248462592 \\n. percentage trainable parameters: 0.36%'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model_path = './peft-dialogue-summary-checkpoint-1695920559'\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=128,\n",
    "    target_modules=[\"q\",\"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias = \"none\",\n",
    "    task_type= TaskType.SEQ_2_SEQ_LM,)\n",
    "\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype = torch.bfloat16)\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(\n",
    "        original_model,\n",
    "        peft_model_path,\n",
    "        lora_config = lora_config,\n",
    "        torch_dtype = torch.bfloat16,\n",
    "        device_map =\"auto\",\n",
    "        is_trainable=True\n",
    ")\n",
    "\n",
    "\n",
    "print_number_of_trainable_parameters(peft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trainable model parameters: 885505\\nall model parameters: 248463361 \\n. percentage trainable parameters: 0.36%'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare model for PPO training\n",
    "# value head addition convert a output token to scaler values needed for PPO training\n",
    "\n",
    "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(peft_model,\n",
    "                                                            torch_dtype= torch.bfloat16,\n",
    "                                                            is_trainable=True)\n",
    "\n",
    "print_number_of_trainable_parameters(ppo_model)\n",
    "# print(ppo_model.v_head)                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trainable model parameters: 0\\nall model parameters: 248463361 \\n. percentage trainable parameters: 0.00%'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a reference model berore PPO training to fix reward hacking happening during RLHF\n",
    "ref_model = create_reference_model(ppo_model)\n",
    "print_number_of_trainable_parameters(ref_model) # reference model is not trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Reward Model\n",
    "\n",
    "Using Facebook's roberta based hate speech model for reward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'not offensive', 1: 'offensive'}\n"
     ]
    }
   ],
   "source": [
    "toxicity_model_name= \"DaNLP/da-electra-hatespeech-detection\"\n",
    "# toxicity_model_name = \"nicholasKluge/ToxicityModel\"\n",
    "toxicity_tokenizer = AutoTokenizer.from_pretrained(toxicity_model_name, device_map =\"cuda\")\n",
    "toxicity_model = AutoModelForSequenceClassification.from_pretrained(toxicity_model_name)\n",
    "print(toxicity_model.config.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love you\n",
      "probs  [not offensive, offensive]: [0.9983037710189819, 0.0016961833462119102]\n"
     ]
    }
   ],
   "source": [
    "# how to use reward model\n",
    "toxicity_model = toxicity_model.to(\"cuda\")\n",
    "non_toxic_text = \"love you\"\n",
    "print(non_toxic_text)\n",
    "toxicity_input_ids = toxicity_tokenizer(non_toxic_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "logits = toxicity_model(input_ids = toxicity_input_ids).logits\n",
    "prob = logits.softmax(dim=-1).tolist()[0]\n",
    "print(f\"probs  [not offensive, offensive]: {prob}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring args : ({'tok_k': None, 'function_to_apply': 'softmax', 'batch_size': 16},)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward pipe output for love you, [{'label': 'not offensive', 'score': 0.9983037710189819}]\n"
     ]
    }
   ],
   "source": [
    "#use a HF inference pipeline for reward getting\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "reward_pipe = pipeline(\"sentiment-analysis\",\n",
    "                        model = toxicity_model,\n",
    "                        tokenizer=toxicity_tokenizer,\n",
    "                        device =0)\n",
    "\n",
    "reward_logits_kwargs = {\n",
    "    \"tok_k\": None, # return all scores\n",
    "    \"function_to_apply\": \"none\",\n",
    "    \"batch_size\":16\n",
    "}\n",
    "\n",
    "reward_probs_kwargs = {\n",
    "    \"tok_k\": None, # return all scores\n",
    "    \"function_to_apply\": \"softmax\",\n",
    "    \"batch_size\":16\n",
    "}\n",
    "\n",
    "print(f\"reward pipe output for {non_toxic_text}, {reward_pipe(non_toxic_text,reward_probs_kwargs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use evaluate lib for toxicity measurement for the model, it directly evaluates the model on toxicity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'not offensive': 0, 'offensive': 1}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxicity_model.config.label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toxicity': [0.0016961980145424604]}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "non_toxic_text = \"love you\"\n",
    "toxicity_evaluator = evaluate.load(\"toxicity\", 'DaNLP/da-electra-hatespeech-detection', module_type=\"measurement\")\n",
    "toxicity_score = toxicity_evaluator.compute(predictions=[non_toxic_text], toxic_label = 'offensive')\n",
    "toxicity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deffine a function to calculate the mean toxicity score for a model\n",
    "\n",
    "def evaluate_toxicity(model,\n",
    "                    toxicity_evaluator,\n",
    "                    dataset,\n",
    "                    tokenizer,\n",
    "                    num_samples):\n",
    "    \n",
    "    max_new_tokens = 200\n",
    "\n",
    "    # dataset = dataset.filter(lambda x: x[\"label\"] == 1)\n",
    "\n",
    "    toxicities = []\n",
    "    input_text = []\n",
    "\n",
    "    for i, sample in tqdm(enumerate(dataset)):\n",
    "        input_text = sample[\"query\"]\n",
    "\n",
    "        if i> num_samples:\n",
    "            break\n",
    "\n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "        generation_config = GenerationConfig(max_new_tokens = max_new_tokens,\n",
    "                                             top_k=0.0,\n",
    "                                             top_p=1.0,\n",
    "                                             do_sample=True)\n",
    "\n",
    "        response_token_ids = model.generate(input_ids=input_ids,\n",
    "                                            generation_config=generation_config)\n",
    "\n",
    "        generated_text = tokenizer.decode(response_token_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        toxicity_score = toxicity_evaluator.compute(predictions=[(input_text + \" \"+ generated_text)], toxic_label = 'offensive')                                                       \n",
    "\n",
    "        toxicities.extend(toxicity_score[\"toxicity\"])\n",
    "\n",
    "    \n",
    "    mean = np.mean(toxicities)\n",
    "    std = np.std(toxicities)\n",
    "\n",
    "    return mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wiki_toxic (/home/azureuser/.cache/huggingface/datasets/OxAISH-AL-LLM___wiki_toxic/default/1.0.0/09a67129f85f67f22107b0190f7c32050ef0dce44afeedc6e3e0ab7ab3bd709c)\n",
      "11it [01:19,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean, std toxicity before ppo (0.18388001654635777, 0.26625992794405157)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name,device_map = \"auto\")\n",
    "ds = load_dataset(\"OxAISH-AL-LLM/wiki_toxic\", split=\"test\")\n",
    "mean_toxicity_before_ppo, std_toxicity_before_ppo = evaluate_toxicity(model = ref_model,\n",
    "                                                                      toxicity_evaluator = toxicity_evaluator,\n",
    "                                                                      tokenizer=toxicity_tokenizer,\n",
    "                                                                      dataset =dataset[\"test\"],\n",
    "                                                                      num_samples =10)\n",
    "\n",
    "print(f\"mean, std toxicity before ppo {mean_toxicity_before_ppo, std_toxicity_before_ppo}\")                                                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform RLHF  to detoxify the summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key1': ['value1', 'value3'], 'key2': ['value2', 'value4']}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializer the PPO trainer\n",
    "\n",
    "learning_rate = 5.41e-5\n",
    "max_ppo_epochs = 1\n",
    "mini_batch_size = 4\n",
    "batch_size = 16\n",
    "\n",
    "config = PPOConfig(\n",
    "    model_name = model_name,\n",
    "    learning_rate = learning_rate,\n",
    "    ppo_epochs= max_ppo_epochs,\n",
    "    mini_batch_size= mini_batch_size,\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "\n",
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
    "\n",
    "test_data = [{\"key1\":\"value1\", \"key2\":\"value2\"},{\"key1\":\"value3\", \"key2\":\"value4\"}]\n",
    "collator(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_trainer = PPOTrainer(config=config,\n",
    "                         model=ppo_model,\n",
    "                         ref_model=ref_model,\n",
    "                            tokenizer=tokenizer,\n",
    "                            dataset=dataset[\"train\"],\n",
    "                            data_collator=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obserbe the RL metrics\n",
    "\n",
    "1. objective/kl\n",
    "2. ppo/returns/mean\n",
    "3. ppo/policy/advnatages_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/anaconda/envs/LLM3.10/lib/python3.10/site-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "1it [00:18, 18.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 15.268651962280273\n",
      "ppo/returns/mean: -0.6054368019104004\n",
      "ppo/policy/advantages_mean: -3.824568217680735e-09\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:31, 15.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 14.318596839904785\n",
      "ppo/returns/mean: -0.5726776123046875\n",
      "ppo/policy/advantages_mean: -1.096756996332715e-08\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:49, 16.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 18.28998565673828\n",
      "ppo/returns/mean: -0.7864238023757935\n",
      "ppo/policy/advantages_mean: -2.9557245539990618e-09\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [01:05, 16.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 19.34527015686035\n",
      "ppo/returns/mean: -0.9329463839530945\n",
      "ppo/policy/advantages_mean: -2.053383951761134e-08\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:20, 15.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 12.339771270751953\n",
      "ppo/returns/mean: -0.4130007028579712\n",
      "ppo/policy/advantages_mean: -1.1378542552620274e-08\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [01:35, 15.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 12.884422302246094\n",
      "ppo/returns/mean: -0.44335299730300903\n",
      "ppo/policy/advantages_mean: 1.3281545641063985e-08\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [01:51, 15.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 16.919139862060547\n",
      "ppo/returns/mean: -0.9352494478225708\n",
      "ppo/policy/advantages_mean: 2.514263464092892e-09\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [02:06, 15.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 15.680459022521973\n",
      "ppo/returns/mean: -0.7123470306396484\n",
      "ppo/policy/advantages_mean: -2.0349098406313715e-08\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [02:21, 15.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 12.17045783996582\n",
      "ppo/returns/mean: -0.4999503791332245\n",
      "ppo/policy/advantages_mean: -1.4291950733991143e-08\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:34, 14.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 11.800167083740234\n",
      "ppo/returns/mean: -0.4948999285697937\n",
      "ppo/policy/advantages_mean: 2.8503697180326526e-09\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [02:46, 13.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 11.169166564941406\n",
      "ppo/returns/mean: -0.5076763033866882\n",
      "ppo/policy/advantages_mean: 4.745400516981135e-09\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [03:00, 13.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 15.693375587463379\n",
      "ppo/returns/mean: -0.7878344058990479\n",
      "ppo/policy/advantages_mean: 7.784768385477037e-09\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [03:13, 13.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 13.772385597229004\n",
      "ppo/returns/mean: -0.5478227138519287\n",
      "ppo/policy/advantages_mean: 8.02979105429813e-09\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [03:25, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 7.439396858215332\n",
      "ppo/returns/mean: -0.10541556775569916\n",
      "ppo/policy/advantages_mean: 1.1171917613239657e-08\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [03:37, 12.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 14.839390754699707\n",
      "ppo/returns/mean: -0.6161832809448242\n",
      "ppo/policy/advantages_mean: -2.9621382680034003e-08\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [03:50, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 10.867485046386719\n",
      "ppo/returns/mean: -0.4072226881980896\n",
      "ppo/policy/advantages_mean: 5.745025788428393e-09\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [04:04, 13.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 12.01366901397705\n",
      "ppo/returns/mean: -0.39700138568878174\n",
      "ppo/policy/advantages_mean: -2.939279486469104e-09\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [04:16, 12.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 13.10476016998291\n",
      "ppo/returns/mean: -0.593254566192627\n",
      "ppo/policy/advantages_mean: -1.5807341213758264e-08\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [04:28, 12.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 12.604625701904297\n",
      "ppo/returns/mean: -0.40113598108291626\n",
      "ppo/policy/advantages_mean: 1.677533312260948e-08\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [04:40, 12.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 11.573077201843262\n",
      "ppo/returns/mean: -0.3285127878189087\n",
      "ppo/policy/advantages_mean: 1.2797562121136252e-08\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [04:53, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 9.786053657531738\n",
      "ppo/returns/mean: -0.26008498668670654\n",
      "ppo/policy/advantages_mean: 2.240621910232221e-08\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [05:04, 12.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 13.233003616333008\n",
      "ppo/returns/mean: -0.43858084082603455\n",
      "ppo/policy/advantages_mean: 5.508438150059192e-10\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [05:17, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 10.77065372467041\n",
      "ppo/returns/mean: -0.2846233546733856\n",
      "ppo/policy/advantages_mean: -2.1688741469461092e-08\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [05:28, 11.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 10.439411163330078\n",
      "ppo/returns/mean: -0.369087278842926\n",
      "ppo/policy/advantages_mean: 8.999259115682889e-10\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [05:40, 11.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 9.204517364501953\n",
      "ppo/returns/mean: -0.24764466285705566\n",
      "ppo/policy/advantages_mean: -8.128289152864454e-10\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [05:52, 12.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 10.753318786621094\n",
      "ppo/returns/mean: -0.3263453543186188\n",
      "ppo/policy/advantages_mean: 2.3738701671049967e-08\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [06:03, 11.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 10.338382720947266\n",
      "ppo/returns/mean: -0.28389811515808105\n",
      "ppo/policy/advantages_mean: -2.7425032911310154e-08\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [06:14, 11.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 11.250727653503418\n",
      "ppo/returns/mean: -0.3541765511035919\n",
      "ppo/policy/advantages_mean: -3.6888108123633856e-09\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [06:25, 11.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 9.893604278564453\n",
      "ppo/returns/mean: -0.2711153030395508\n",
      "ppo/policy/advantages_mean: 8.724278188765311e-09\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [06:36, 11.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 11.727471351623535\n",
      "ppo/returns/mean: -0.36738479137420654\n",
      "ppo/policy/advantages_mean: -6.823546616629983e-09\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [06:49, 13.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 10.808866500854492\n",
      "ppo/returns/mean: -0.3813740611076355\n",
      "ppo/policy/advantages_mean: 1.4115292934491208e-08\n",
      "------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_min_length = 100\n",
    "output_max_length = 400\n",
    "\n",
    "output_length_sampler = LengthSampler(output_min_length,\n",
    "                                      output_max_length)\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": 5,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "}\n",
    "\n",
    "reward_kwargs = {\n",
    "    \"top_k\": None, # return all scores\n",
    "    \"function_to_apply\": \"softmax\",\n",
    "    \"batch_size\":16\n",
    "}\n",
    "\n",
    "max_ppo_steps = 30\n",
    "\n",
    "for steps, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "\n",
    "    if steps > max_ppo_steps:\n",
    "        break\n",
    "\n",
    "    prompt_tensors = batch[\"input_ids\"]\n",
    "    summary_tensors = []\n",
    "\n",
    "    for prompt_tensor in prompt_tensors:\n",
    "        max_new_tokens = output_length_sampler()\n",
    "        generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
    "        summary = ppo_trainer.generate(prompt_tensor,\n",
    "                                                    **generation_kwargs)\n",
    "\n",
    "        summary_tensors.append(summary.squeeze()[-max_new_tokens:])\n",
    "\n",
    "    batch[\"response\"] = [tokenizer.decode(summary_tensor, skip_special_tokens=True) for summary_tensor in summary_tensors]\n",
    "\n",
    "    query_response_pairs = [ q+r for q,r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "\n",
    "    rewards = reward_pipe(query_response_pairs, **reward_kwargs)\n",
    "    reward_tensors = [torch.tensor(reward[0][\"score\"]) for reward in rewards]\n",
    "    stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\n",
    "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
    "\n",
    "    print(f'objective/kl: {stats[\"objective/kl\"]}')\n",
    "    print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}')\n",
    "    print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}')\n",
    "    print('-'.join('' for x in range(79)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the model qualitatively\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:43,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean, std toxicity after ppo (0.1282393615692854, 0.09117653166753624)\n",
      "percentage improvement in toxicity 30.25921795207414 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate the toxicity after ppo\n",
    "\n",
    "mean_toxicity_after_ppo, std_toxicity_after_ppo = evaluate_toxicity(model = ppo_model,\n",
    "                                                                        toxicity_evaluator = toxicity_evaluator,\n",
    "                                                                        tokenizer=toxicity_tokenizer,\n",
    "                                                                        dataset =dataset[\"test\"],\n",
    "                                                                        num_samples =5)\n",
    "\n",
    "\n",
    "print(f\"mean, std toxicity after ppo {mean_toxicity_after_ppo, std_toxicity_after_ppo}\")\n",
    "print(\"percentage improvement in toxicity\", ((mean_toxicity_before_ppo - mean_toxicity_after_ppo)*100/mean_toxicity_before_ppo), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the ppo model\n",
    "ppo_model_path = f\"./ppo-dialogue-summary-checkpoint-RLHF-{TIME}\"\n",
    "tokenizer.save_pretrained(ppo_model_path)\n",
    "ppo_model.save_pretrained(ppo_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
